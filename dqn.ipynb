{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DQN Class\n",
    "\n",
    "DQN(NIPS-2013)\n",
    "\"Playing Atari with Deep Reinforcement Learning\"\n",
    "https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "\n",
    "DQN(Nature-2015)\n",
    "\"Human-level control through deep reinforcement learning\"\n",
    "http://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class DQN:\n",
    "\n",
    "    def __init__(self, session: tf.Session, input_size: int, output_size: int, name: str=\"main\") -> None:\n",
    "        \"\"\"DQN Agent can\n",
    "\n",
    "        1) Build network\n",
    "        2) Predict Q_value given state\n",
    "        3) Train parameters\n",
    "\n",
    "        Args:\n",
    "            session (tf.Session): Tensorflow session\n",
    "            input_size (int): Input dimension\n",
    "            output_size (int): Number of discrete actions\n",
    "            name (str, optional): TF Graph will be built under this name scope\n",
    "        \"\"\"\n",
    "        self.session = session\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.net_name = name\n",
    "\n",
    "        self._build_network()\n",
    "\n",
    "    def _build_network(self, h_size=16, l_rate=0.001) -> None:\n",
    "        \"\"\"DQN Network architecture (simple MLP)\n",
    "\n",
    "        Args:\n",
    "            h_size (int, optional): Hidden layer dimension\n",
    "            l_rate (float, optional): Learning rate\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(self.net_name):\n",
    "            self._X = tf.placeholder(tf.float32, [None, self.input_size], name=\"input_x\")\n",
    "            net = self._X\n",
    "\n",
    "            net = tf.layers.dense(net, h_size, activation=tf.nn.relu)\n",
    "            net = tf.layers.dense(net, self.output_size)\n",
    "            self._Qpred = net\n",
    "\n",
    "            self._Y = tf.placeholder(tf.float32, shape=[None, self.output_size])\n",
    "            self._loss = tf.losses.mean_squared_error(self._Y, self._Qpred)\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=l_rate)\n",
    "            self._train = optimizer.minimize(self._loss)\n",
    "\n",
    "    def predict(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Returns Q(s, a)\n",
    "\n",
    "        Args:\n",
    "            state (np.ndarray): State array, shape (n, input_dim)\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Q value array, shape (n, output_dim)\n",
    "        \"\"\"\n",
    "        x = np.reshape(state, [-1, self.input_size])\n",
    "        return self.session.run(self._Qpred, feed_dict={self._X: x})\n",
    "\n",
    "    def update(self, x_stack: np.ndarray, y_stack: np.ndarray) -> list:\n",
    "        \"\"\"Performs updates on given X and y and returns a result\n",
    "\n",
    "        Args:\n",
    "            x_stack (np.ndarray): State array, shape (n, input_dim)\n",
    "            y_stack (np.ndarray): Target Q array, shape (n, output_dim)\n",
    "\n",
    "        Returns:\n",
    "            list: First element is loss, second element is a result from train step\n",
    "        \"\"\"\n",
    "        feed = {\n",
    "            self._X: x_stack,\n",
    "            self._Y: y_stack\n",
    "        }\n",
    "        return self.session.run([self._loss, self._train], feed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
